{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User rating based on the review - RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "tf.random.set_random_seed(47)\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.layers import Dense, Dropout, Embedding, LSTM, Bidirectional\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features = 20000\n",
    "# cut texts after this number of words (among top max_features most common words)\n",
    "maxlen = 100\n",
    "batch_size = 256\n",
    "epochs = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've already preprocessed our text data when we were training TF-IDF based classifier, so now we're able to load it and skip preprocessing step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['потрясающе красивый график космос игра полюбить наличие интересный осмысленный сюжет удобный управление',\n",
       "  'заметный труд область теоретический антропология этнография язык изложение доступный качество перевод достойный замечательный серия этнографический библиотека',\n",
       "  'отличный продолжение отличный игра',\n",
       "  'графика неплохой остальное скучно тупо проехать определенный участок хороший управление вызывать никакой приятный ощущение игра график',\n",
       "  'таки удерживаться написать топ скоро стереть прочитывать ужасный игра star wars empire at war dvd поискать нормальный сюжет стратегия вовсе провал убеждаться браться план игра отстой хороший стратегия эпизод star wars star wars galactic battlegrounds играть понимать'],\n",
       " [5, 5, 5, 3, 1])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"auxiliary/reviews_dataset_preprocessed.pkl\", \"rb\") as f:\n",
    "    X = pickle.load(f)\n",
    "\n",
    "with open(\"auxiliary/reviews_dataset.pkl\", \"rb\") as f:\n",
    "    _, y = pickle.load(f)\n",
    "\n",
    "X[:5], y[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=37, stratify=y\n",
    ")\n",
    "\n",
    "# save an example sentence for later\n",
    "example_idx = 8\n",
    "example_review = X_train[example_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 203040 unique tokens\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer(num_words=max_features)\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "print(f\"Found {len(word_index)} unique tokens\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (615400, 100)\n",
      "X_test shape: (153851, 100)\n"
     ]
    }
   ],
   "source": [
    "X_train = tokenizer.texts_to_sequences(X_train)\n",
    "X_test = tokenizer.texts_to_sequences(X_test)\n",
    "\n",
    "X_train = pad_sequences(X_train, maxlen=maxlen)\n",
    "X_test = pad_sequences(X_test, maxlen=maxlen)\n",
    "\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train shape: (615400, 5)\n",
      "y_test shape: (153851, 5)\n"
     ]
    }
   ],
   "source": [
    "# subtract 1 because keras to_categorical() expects integers from 0 to num_classes\n",
    "y_train = to_categorical(np.array(y_train) - 1)\n",
    "y_test = to_categorical(np.array(y_test) - 1)\n",
    "\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"y_test shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's the final representation of data in a way it'll be fed to our network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  4,  6, 46, 13],\n",
       "      dtype=int32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[example_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zeros up to the last 4 numbers is padding. The meaningful indices in the end correspond to words in the following sentence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'купить отличный вещь удобный'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make sure it corresponds to the representation above by looking up word indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "купить : 4\n",
      "отличный : 6\n",
      "вещь : 46\n",
      "удобный : 13\n"
     ]
    }
   ],
   "source": [
    "for word in example_review.split():\n",
    "    print(f\"{word} : {word_index[word]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 100, 128)          2560000   \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 128)               131584    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 5)                 645       \n",
      "=================================================================\n",
      "Total params: 2,692,229\n",
      "Trainable params: 2,692,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 128, input_length=maxlen))\n",
    "# model.add(Bidirectional(LSTM(64)))\n",
    "# model.add(Dropout(0.5))\n",
    "model.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(5, activation=\"softmax\"))\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 615400 samples, validate on 153851 samples\n",
      "Epoch 1/4\n",
      "615400/615400 [==============================] - 1349s 2ms/step - loss: 0.8126 - acc: 0.7062 - val_loss: 0.7676 - val_acc: 0.7186\n",
      "Epoch 2/4\n",
      "615400/615400 [==============================] - 1260s 2ms/step - loss: 0.7466 - acc: 0.7243 - val_loss: 0.7605 - val_acc: 0.7206\n",
      "Epoch 3/4\n",
      "615400/615400 [==============================] - 1264s 2ms/step - loss: 0.7173 - acc: 0.7338 - val_loss: 0.7674 - val_acc: 0.7201\n",
      "Epoch 4/4\n",
      "615400/615400 [==============================] - 1279s 2ms/step - loss: 0.6898 - acc: 0.7438 - val_loss: 0.7765 - val_acc: 0.7167\n"
     ]
    }
   ],
   "source": [
    "checkpoint = ModelCheckpoint(\n",
    "    \"auxiliary/lstm_best_weights.h5\",\n",
    "    monitor=\"val_acc\",\n",
    "    verbose=1,\n",
    "    save_best_only=True,\n",
    "    mode=\"max\",\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=[X_test, y_test],\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "tensorflow-training",
   "language": "python",
   "name": "tensorflow-training"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
